{"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f789df4f81084626b4237002515255ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1f694c7961924aa78f135c00425d37dd","IPY_MODEL_be6d3624d6244196b79d90cf54cd248f","IPY_MODEL_c90a64d12b28470c89f64d38da1b7c6a"],"layout":"IPY_MODEL_a7a826040a164015bc588f572f04f350"}},"1f694c7961924aa78f135c00425d37dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_825e8f5e68af4b989bb4fba75b2335e1","placeholder":"​","style":"IPY_MODEL_6728939f6e15498d81a816deeadc49ab","value":"Loading checkpoint shards: 100%"}},"be6d3624d6244196b79d90cf54cd248f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34179dad108a4b6da5faf2e86aa42b58","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_607313b6a93f45e4b261b1c63b24604e","value":7}},"c90a64d12b28470c89f64d38da1b7c6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fb8bb56ec594b8a8d27ad3fda854c82","placeholder":"​","style":"IPY_MODEL_f80f5894f762436085243107de9a216f","value":" 7/7 [00:04&lt;00:00,  1.80it/s]"}},"a7a826040a164015bc588f572f04f350":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"825e8f5e68af4b989bb4fba75b2335e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6728939f6e15498d81a816deeadc49ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34179dad108a4b6da5faf2e86aa42b58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"607313b6a93f45e4b261b1c63b24604e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2fb8bb56ec594b8a8d27ad3fda854c82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f80f5894f762436085243107de9a216f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7567407,"sourceType":"datasetVersion","datasetId":4405657}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U transformers --quiet\n!pip install -q pillow accelerate einops --quiet","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iLa1NuymnTMr","outputId":"3b792ca9-1fc0-4b82-90d7-4c07db02006a","execution":{"iopub.status.busy":"2024-02-06T04:18:11.086749Z","iopub.execute_input":"2024-02-06T04:18:11.087074Z","iopub.status.idle":"2024-02-06T04:18:48.346461Z","shell.execute_reply.started":"2024-02-06T04:18:11.087045Z","shell.execute_reply":"2024-02-06T04:18:48.345379Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer #AutoModelCausalLM for generation task\nfrom PIL import Image","metadata":{"id":"Kt58LGl4nfDS","execution":{"iopub.status.busy":"2024-02-06T04:29:53.012536Z","iopub.execute_input":"2024-02-06T04:29:53.013499Z","iopub.status.idle":"2024-02-06T04:29:53.017651Z","shell.execute_reply.started":"2024-02-06T04:29:53.013463Z","shell.execute_reply":"2024-02-06T04:29:53.016528Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"torch.set_default_device(\"cuda\") #setting the default device to cuda","metadata":{"id":"g3gYEVvVni9P","execution":{"iopub.status.busy":"2024-02-06T04:20:04.326326Z","iopub.execute_input":"2024-02-06T04:20:04.326794Z","iopub.status.idle":"2024-02-06T04:20:04.333095Z","shell.execute_reply.started":"2024-02-06T04:20:04.326766Z","shell.execute_reply":"2024-02-06T04:20:04.331993Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#setting up the model\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"MILVLG/imp-v1-3b\", #this is the model imported from hugging face\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\n#setting up the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n    \"MILVLG/imp-v1-3b\",\n    trust_remote_code=True\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["f789df4f81084626b4237002515255ed","1f694c7961924aa78f135c00425d37dd","be6d3624d6244196b79d90cf54cd248f","c90a64d12b28470c89f64d38da1b7c6a","a7a826040a164015bc588f572f04f350","825e8f5e68af4b989bb4fba75b2335e1","6728939f6e15498d81a816deeadc49ab","34179dad108a4b6da5faf2e86aa42b58","607313b6a93f45e4b261b1c63b24604e","2fb8bb56ec594b8a8d27ad3fda854c82","f80f5894f762436085243107de9a216f"]},"id":"j1p9U6kdnjAX","outputId":"9ffd57c5-dbd9-499e-aa81-f8cc80e9802c","execution":{"iopub.status.busy":"2024-02-06T04:20:24.748505Z","iopub.execute_input":"2024-02-06T04:20:24.748860Z","iopub.status.idle":"2024-02-06T04:21:24.433764Z","shell.execute_reply.started":"2024-02-06T04:20:24.748832Z","shell.execute_reply":"2024-02-06T04:21:24.432857Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.69k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f2b948022b446c1af94193d8cfb974e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_imp.py:   0%|          | 0.00/7.04k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f108054f5dab4746abd066ca0ae43ee5"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/MILVLG/imp-v1-3b:\n- configuration_imp.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_imp.py:   0%|          | 0.00/47.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b2f828de01240a18b3a3eedba6a7291"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vision_encoder.py:   0%|          | 0.00/23.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"002d1e53000347b6b765f71c36b6e072"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/MILVLG/imp-v1-3b:\n- vision_encoder.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\nA new version of the following files was downloaded from https://huggingface.co/MILVLG/imp-v1-3b:\n- modeling_imp.py\n- vision_encoder.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n2024-02-06 04:20:28.856147: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-06 04:20:28.856245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-06 04:20:29.029239: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/79.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83c62d390e084430bfcc8db192b4a2a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ed57f4ab1ce49b1b36fbe4644e9d92e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00007.safetensors:   0%|          | 0.00/996M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c32995025a75400187af830829ad0a68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00007.safetensors:   0%|          | 0.00/997M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85732cc0620b47508aa9f51e49494dd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00007.safetensors:   0%|          | 0.00/997M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0e8025a0baf42fa850268285511600c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00007.safetensors:   0%|          | 0.00/997M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d90ec53a2ba64eedb0b26db8977dd125"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00007.safetensors:   0%|          | 0.00/997M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d833ca42b97e4e6081e84491457829fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00007.safetensors:   0%|          | 0.00/1.02G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5b3f53eb22b4c618186508955b74106"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00007-of-00007.safetensors:   0%|          | 0.00/370M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11c1688d31124a1ab1bb335f91715851"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ae6ae056379460a98931c154a874a51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a02da6d17c54d619ba2eeca5d06640b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/8.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02c6cd9a12ea407788894470576a8a93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/999k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff6215095bcb44fb95c28ff268116721"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdb5bc6067e14e8aa8ca5fd88942a6bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91bd374069424078b4295ac5025e3956"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"746bb89573ab4ecdb6946ccece0d35b0"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"text = \"\"\"A chat between a curious user and an artificial intelligence assistant.\nThe assistant generates helpful and detailed answer after analyzing an image.\nUSER: <image>\\nAnalyze the image. ASSISTANT:\"\"\"\nimage = Image.open(\"/kaggle/input/kidney-image/Cross-section-kidney-blood-vessels.jpg\")","metadata":{"id":"vomEk2XRnjDp","execution":{"iopub.status.busy":"2024-02-06T04:29:58.526561Z","iopub.execute_input":"2024-02-06T04:29:58.527424Z","iopub.status.idle":"2024-02-06T04:29:58.634505Z","shell.execute_reply.started":"2024-02-06T04:29:58.527385Z","shell.execute_reply":"2024-02-06T04:29:58.633531Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(model) #architecture of model","metadata":{"execution":{"iopub.status.busy":"2024-02-06T04:31:14.216063Z","iopub.execute_input":"2024-02-06T04:31:14.217227Z","iopub.status.idle":"2024-02-06T04:31:14.227263Z","shell.execute_reply.started":"2024-02-06T04:31:14.217187Z","shell.execute_reply":"2024-02-06T04:31:14.226339Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"ImpForCausalLM(\n  (transformer): ImpModel(\n    (embd): Embedding(\n      (wte): Embedding(51200, 2560)\n      (drop): Dropout(p=0.0, inplace=False)\n    )\n    (h): ModuleList(\n      (0-31): 32 x ParallelBlock(\n        (ln): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n        (mixer): MHA(\n          (rotary_emb): RotaryEmbedding()\n          (Wqkv): Linear(in_features=2560, out_features=7680, bias=True)\n          (out_proj): Linear(in_features=2560, out_features=2560, bias=True)\n          (inner_attn): SelfAttention(\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n          (inner_cross_attn): CrossAttention(\n            (drop): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (mlp): MLP(\n          (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n          (fc2): Linear(in_features=10240, out_features=2560, bias=True)\n          (act): NewGELUActivation()\n        )\n      )\n    )\n    (vision_tower): VisionTower(\n      (vision_tower): SiglipVisionModel(\n        (vision_model): SiglipVisionTransformer(\n          (embeddings): SiglipVisionEmbeddings(\n            (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n            (position_embedding): Embedding(729, 1152)\n          )\n          (encoder): SiglipEncoder(\n            (layers): ModuleList(\n              (0-25): 26 x SiglipEncoderLayer(\n                (self_attn): SiglipAttention(\n                  (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n                  (v_proj): Linear(in_features=1152, out_features=1152, bias=True)\n                  (q_proj): Linear(in_features=1152, out_features=1152, bias=True)\n                  (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n                )\n                (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n                (mlp): SiglipMLP(\n                  (activation_fn): PytorchGELUTanh()\n                  (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n                  (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n                )\n                (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n              )\n            )\n          )\n          (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n          (head): Identity()\n        )\n      )\n    )\n    (mm_projector): Sequential(\n      (0): Linear(in_features=1152, out_features=2560, bias=True)\n      (1): GELU(approximate='none')\n      (2): Linear(in_features=2560, out_features=2560, bias=True)\n    )\n  )\n  (lm_head): CausalLMHead(\n    (ln): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n    (linear): Linear(in_features=2560, out_features=51200, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### The provided code performs text and image generation using a language model. Here's a breakdown:\n\n- Tokenization: It tokenizes the input text using the tokenizer and converts it into PyTorch tensors (return_tensors=\"pt\").\n- Image Preprocessing: The code preprocesses the input image using the model.image_preprocess function, resulting in a tensor (torch array) representing the image.\n- Text Generation: The model.generate function generates text based on the tokenized input (input_ids). It limits the output to a maximum of 800 new tokens (max_new_tokens=800), incorporating information from the provided image. The use_cache=True parameter suggests the use of cached information during generation.\n- Decoding and Printing: The generated text (output_ids) is decoded using the tokenizer, skipping special tokens. The decoded text is then printed after stripping leading and trailing whitespaces.","metadata":{}},{"cell_type":"code","source":"input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\nimage_tensor = model.image_preprocess(image) #the tensor (torch array) of the image\noutput_ids = model.generate(\n    input_ids,\n    max_new_tokens=6000,\n    images=image_tensor,\n    use_cache=True)[0]\nprint(tokenizer.decode(output_ids[input_ids.shape[1]:], skip_special_tokens=True).strip())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PGw7ufRNnjHr","outputId":"343f9a55-469d-439f-cc0b-d6a36554fe45","execution":{"iopub.status.busy":"2024-02-06T04:38:54.966650Z","iopub.execute_input":"2024-02-06T04:38:54.967002Z","iopub.status.idle":"2024-02-06T04:39:00.436980Z","shell.execute_reply.started":"2024-02-06T04:38:54.966976Z","shell.execute_reply":"2024-02-06T04:39:00.435894Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"The image is a detailed drawing of the human kidney, showcasing its various parts and structures. The drawing is color-coded, with red, blue, and white colors representing different components of the kidney. The drawing is labeled with the name \"Kidney\" and provides a comprehensive view of the organ's anatomy.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"_LY71leFz96q"},"execution_count":null,"outputs":[]}]}